{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Megvii-BaseDetection/YOLOX.git"
      ],
      "metadata": {
        "id": "2hUCMO3CtYcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd YOLOX\n",
        "!pip3 install -v -e ."
      ],
      "metadata": {
        "id": "GQgKFSRltbiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "metadata": {
        "id": "YV3-Itouuz5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd YOLOX"
      ],
      "metadata": {
        "id": "nWYtHDZek_2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q geopandas\n",
        "!pip install -q rasterio\n",
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "i0AIT6ZSZvkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "from yolox.models import YOLOX\n",
        "from yolox.data import COCODataset, get_yolox_datadir\n",
        "import torchvision.transforms as T\n",
        "import yolox"
      ],
      "metadata": {
        "id": "1NBQnvGYZx7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning\n",
        "pytorch_lightning.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Nkv2TjAT4ns8",
        "outputId": "e319ab69-9726-4c2a-c03b-196d543af9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5BcotRXYxTQ"
      },
      "outputs": [],
      "source": [
        "class YOLOXModel(LightningModule):\n",
        "    def __init__(self, batch_size=1, num_workers=4):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "        self.model = YOLOX()  # Initialize YOLOX model\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        imgs, targets = batch\n",
        "        outputs = self.model(imgs)\n",
        "        loss = self.model.loss(outputs, targets)\n",
        "        self.log('train_loss', loss)\n",
        "        print(\"loss: \", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, targets = batch\n",
        "        outputs = self.model(imgs)\n",
        "        loss = self.model.loss(outputs, targets)\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
        "        scheduler = {\n",
        "            'scheduler': torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1),\n",
        "            'interval': 'epoch',\n",
        "            'frequency': 1\n",
        "        }\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "class DataModule_COCO(LightningModule):\n",
        "    def __init__(self, data_dir, batch_size=1, num_workers=4):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.transform= T.Resize(512)\n",
        "\n",
        "        self.coco_train = COCODataset(\n",
        "            data_dir=os.path.join(data_dir, './'),  # Path to COCO train dataset\n",
        "            json_file=os.path.join(data_dir, \"coco_format_12_4/project_building_properties_right-coco-1/annotations/instances_default.json\"),\n",
        "            name=\"coco_train_dataset\",\n",
        "            img_size=(512,512),  # Input image size\n",
        "            preproc=None  # Preprocessing function if needed\n",
        "        )\n",
        "        self.coco_val = COCODataset(\n",
        "            data_dir=os.path.join(data_dir, './'),  # Path to COCO validation dataset\n",
        "            img_size=(512,512),  # Input image size\n",
        "            json_file=os.path.join(data_dir, \"coco_format_12_4/project_building_properties_left-coco-1/annotations/instances_default.json\"),\n",
        "            name=\"coco_val_dataset\",\n",
        "            preproc=None  # Preprocessing function if needed\n",
        "        )\n",
        "        print(len(self.coco_train), len(self.coco_val))\n",
        "\n",
        "\n",
        "    def my_collate_fn(batch):\n",
        "      # `batch` is a list of samples, where each sample is a tuple (image, target)\n",
        "      #print(batch)\n",
        "      images = [torch.from_numpy(item[0]) for item in batch]  # Convert NumPy array to PyTorch tensor\n",
        "      targets = [torch.tensor(item[1]) for item in batch]\n",
        "      # Process and return the batched samples\n",
        "      # Example: Returning images and targets as tensors\n",
        "      return torch.stack(images), targets\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # Return the training DataLoader\n",
        "        #transform = transforms.Compose([transforms.ToTensor()])\n",
        "        train_dataset = self.coco_train\n",
        "        train_loader = DataLoader(self.coco_train, batch_size=self.batch_size, num_workers=self.num_workers, collate_fn=self.my_collate_fn, shuffle=True)\n",
        "        return train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # Return the training DataLoader\n",
        "        #transform = transforms.Compose([transforms.ToTensor()])\n",
        "        val_dataset = self.coco_val\n",
        "        val_loader = DataLoader(self.coco_val, batch_size=self.batch_size, num_workers=self.num_workers, collate_fn=self.my_collate_fn, shuffle=False)\n",
        "        return val_loader\n",
        "\n",
        "\n",
        "# Set your data directory containing COCO format dataset\n",
        "data_dir = 'mapillary_images'\n",
        "\n",
        "model = YOLOXModel()\n",
        "datamod = DataModule_COCO(data_dir)\n",
        "trainer = Trainer(max_epochs=20) # Adjust max_epochs as needed\n",
        "print(\"training\")\n",
        "trainer.fit(model, datamodule=datamod)\n",
        "# Evaluation\n",
        "#trainer.test(model, datamodule=datamod) #.val_loader)"
      ]
    }
  ]
}